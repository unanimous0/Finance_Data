"""
ì¼ë³„ ë°ì´í„° ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ëŒ€ìƒ: ohlcv_daily, market_cap_daily, investor_trading
ì‹¤í–‰: ë§¤ì¼ 16:30 (schedulers/daily_scheduler.py ë˜ëŠ” ë‹¨ë… ì‹¤í–‰)

ì‚¬ìš©ë²•:
    python scripts/daily_update.py           # ìë™ ë‚ ì§œ ê°ì§€
    python scripts/daily_update.py 20260220  # íŠ¹ì • ë‚ ì§œ ì§€ì •
"""

import sys
import io
import time
import threading
import traceback
from pathlib import Path
from datetime import date, datetime, timedelta
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from zoneinfo import ZoneInfo

import psycopg2
import psycopg2.extras

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.settings import settings
from collectors.infomax import InfomaxClient

KST = ZoneInfo("Asia/Seoul")
REPORTS_DIR = project_root / "reports"
REPORTS_DIR.mkdir(exist_ok=True)

# ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
# ê³µìœ  rate limiter(60íšŒ/ë¶„)ë¥¼ Nê°œ ìŠ¤ë ˆë“œê°€ ë‚˜ëˆ  ì“°ë¯€ë¡œ rate limit ì´ˆê³¼ ì—†ìŒ.
# ë„¤íŠ¸ì›Œí¬ latency(~0.1ì´ˆ)ì™€ throttle ëŒ€ê¸°ë¥¼ ì˜¤ë²„ë©í•´ ì²˜ë¦¬ìœ¨ í–¥ìƒ.
MAX_WORKERS = 4

# íŠ¹ì´ì‚¬í•­ ì„ê³„ê°’
THRESHOLD_PRICE_CHANGE  = 0.295   # ê°€ê²© ë³€ë™ 29.5% ì´ìƒ (ìƒí•œ/í•˜í•œê°€ ê·¼ì ‘)
THRESHOLD_VOLUME_ZERO   = True    # ê±°ë˜ëŸ‰ 0 = ê±°ë˜ì •ì§€
THRESHOLD_LARGE_NET_BUY = 5e10    # ìˆœë§¤ìˆ˜ 500ì–µ ì´ìƒ (ê±°ì•¡ ìœ ì…/ì´íƒˆ)


# â”€â”€ DB ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_conn():
    return psycopg2.connect(
        host=settings.DB_HOST,
        dbname=settings.DB_NAME,
        user=settings.DB_USER,
        password=settings.DB_PASSWORD,
    )


# â”€â”€ ë‚ ì§œ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_update_range(conn) -> tuple[date, date]:
    """
    ì—…ë°ì´íŠ¸ ë²”ìœ„ ê²°ì •
    start: DBì˜ ë§ˆì§€ë§‰ ë‚ ì§œ + 1ì¼
    end:   ì–´ì œ (ë‹¹ì¼ ë°ì´í„°ëŠ” ì¥ ë§ˆê° í™•ì¸ í›„ ë‹¤ìŒë‚  ìˆ˜ì§‘)
    """
    with conn.cursor() as cur:
        cur.execute("SELECT MAX(time) FROM ohlcv_daily")
        last_date = cur.fetchone()[0]

    if last_date is None:
        raise ValueError("ohlcv_dailyì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    start = last_date + timedelta(days=1)
    end   = datetime.now(KST).date() - timedelta(days=1)  # ì–´ì œê¹Œì§€ (ë‹¹ì¼ ì¥ ë§ˆê° ì „ ì‹¤í–‰ ë°©ì§€)
    return start, end


# â”€â”€ ì¢…ëª© ëª©ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_stocks(conn, include_etf: bool = True) -> list[tuple[str, str]]:
    """(stock_code, stock_name) ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    with conn.cursor() as cur:
        if include_etf:
            cur.execute("""
                SELECT stock_code, stock_name
                FROM stocks
                WHERE is_active = TRUE
                ORDER BY stock_code
            """)
        else:
            cur.execute("""
                SELECT stock_code, stock_name
                FROM stocks
                WHERE is_active = TRUE
                  AND market IN ('KOSPI', 'KOSDAQ')
                ORDER BY stock_code
            """)
        return cur.fetchall()


# â”€â”€ ë³‘ë ¬ ìˆ˜ì§‘ worker (module-level, pickle ê°€ëŠ¥) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _fetch_hist(client, code, name, start, end):
    rows = client.get_hist(code, start, end)
    return code, name, rows


def _fetch_investor(client, code, name, start, end):
    rows = client.get_investor(code, start, end)
    return code, name, rows


# â”€â”€ DB UPSERT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OHLCV_SQL = """
INSERT INTO ohlcv_daily
    (time, stock_code, open_price, high_price, low_price, close_price, volume, trading_value)
VALUES %s
ON CONFLICT (time, stock_code) DO UPDATE SET
    open_price    = EXCLUDED.open_price,
    high_price    = EXCLUDED.high_price,
    low_price     = EXCLUDED.low_price,
    close_price   = EXCLUDED.close_price,
    volume        = EXCLUDED.volume,
    trading_value = EXCLUDED.trading_value
WHERE (ohlcv_daily.open_price, ohlcv_daily.high_price, ohlcv_daily.low_price,
       ohlcv_daily.close_price, ohlcv_daily.volume, ohlcv_daily.trading_value)
   IS DISTINCT FROM
      (EXCLUDED.open_price, EXCLUDED.high_price, EXCLUDED.low_price,
       EXCLUDED.close_price, EXCLUDED.volume, EXCLUDED.trading_value)
"""

MKTCAP_SQL = """
INSERT INTO market_cap_daily (time, stock_code, market_cap)
VALUES %s
ON CONFLICT (time, stock_code) DO UPDATE SET
    market_cap = EXCLUDED.market_cap
WHERE market_cap_daily.market_cap IS DISTINCT FROM EXCLUDED.market_cap
"""

INVESTOR_SQL = """
INSERT INTO investor_trading
    (time, stock_code, investor_type, net_buy_value, net_buy_volume)
VALUES %s
ON CONFLICT (time, stock_code, investor_type) DO UPDATE SET
    net_buy_value  = EXCLUDED.net_buy_value,
    net_buy_volume = EXCLUDED.net_buy_volume
WHERE (investor_trading.net_buy_value, investor_trading.net_buy_volume)
   IS DISTINCT FROM
      (EXCLUDED.net_buy_value, EXCLUDED.net_buy_volume)
"""


def upsert_batch(conn, sql: str, rows: list[tuple]) -> tuple[int, int]:
    """
    Returns: (changed_rows, total_rows)
    changed_rows: ì‹¤ì œ INSERTë˜ê±°ë‚˜ ê°’ì´ ë‹¬ë¼ì„œ UPDATEëœ ê±´ìˆ˜
    total_rows:   ì‹œë„í•œ ì „ì²´ ê±´ìˆ˜ (changed + skipped)
    """
    if not rows:
        return 0, 0
    with conn.cursor() as cur:
        psycopg2.extras.execute_values(cur, sql, rows, page_size=500)
        changed = cur.rowcount  # WHERE ì¡°ê±´ ë¶ˆë§Œì¡±(ê°’ ë™ì¼)ì€ ì¹´ìš´íŠ¸ ì•ˆ ë¨
    conn.commit()
    return changed, len(rows)


# â”€â”€ íŠ¹ì´ì‚¬í•­ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_anomalies(ohlcv_rows: list[dict],
                      investor_rows: list[dict],
                      prev_close: dict) -> list[dict]:
    """
    íŠ¹ì´ì‚¬í•­ ëª©ë¡ ë°˜í™˜
    ê° í•­ëª©: {"type", "stock_code", "stock_name", "date", "detail", "value"}
    """
    anomalies = []

    # â”€â”€ OHLCV íŠ¹ì´ì‚¬í•­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for r in ohlcv_rows:
        code  = r["stock_code"]
        name  = r.get("stock_name", code)
        dt    = r["date"]
        close = r["close_price"] or 0
        high  = r["high_price"]  or 0
        low   = r["low_price"]   or 0
        vol   = r["volume"]      or 0

        # ê±°ë˜ëŸ‰ 0 â†’ ê±°ë˜ì •ì§€/ê´€ë¦¬ì¢…ëª©
        if vol == 0 and close > 0:
            anomalies.append({
                "type": "ê±°ë˜ì •ì§€",
                "stock_code": code, "stock_name": name, "date": dt,
                "detail": f"ê±°ë˜ëŸ‰=0, ì¢…ê°€={close:,}ì›",
                "value": 0,
            })

        # OHLCV ë…¼ë¦¬ ì˜¤ë¥˜
        if high and low and high < low:
            anomalies.append({
                "type": "OHLCVì˜¤ë¥˜",
                "stock_code": code, "stock_name": name, "date": dt,
                "detail": f"ê³ ê°€({high:,}) < ì €ê°€({low:,})",
                "value": high - low,
            })

        # ì „ì¼ ëŒ€ë¹„ ê¸‰ë“±ë½ (ìƒ/í•˜í•œê°€ ê·¼ì ‘)
        prev = prev_close.get(code)
        if prev and prev > 0 and close > 0:
            chg_rate = abs(close - prev) / prev
            if chg_rate >= THRESHOLD_PRICE_CHANGE:
                direction = "ê¸‰ë“±" if close > prev else "ê¸‰ë½"
                anomalies.append({
                    "type": f"ê°€ê²©{direction}",
                    "stock_code": code, "stock_name": name, "date": dt,
                    "detail": f"ì „ì¼ì¢…ê°€={prev:,}ì› â†’ ë‹¹ì¼ì¢…ê°€={close:,}ì› ({chg_rate*100:+.1f}%)",
                    "value": chg_rate,
                })

    # â”€â”€ íˆ¬ìì ìˆ˜ê¸‰ íŠ¹ì´ì‚¬í•­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì¢…ëª©ë³„ ë‚ ì§œë³„ ìˆœë§¤ìˆ˜ ì§‘ê³„
    net_by_stock = defaultdict(lambda: defaultdict(int))
    names = {}
    for r in investor_rows:
        code = r["stock_code"]
        dt   = r["date"]
        net_by_stock[code][dt] += (r["net_buy_value"] or 0)
        names[code] = r.get("stock_name", code)

    for code, dates in net_by_stock.items():
        for dt, net_total in dates.items():
            if abs(net_total) >= THRESHOLD_LARGE_NET_BUY:
                direction = "ëŒ€ê·œëª¨ìˆœë§¤ìˆ˜" if net_total > 0 else "ëŒ€ê·œëª¨ìˆœë§¤ë„"
                anomalies.append({
                    "type": direction,
                    "stock_code": code, "stock_name": names.get(code, code),
                    "date": dt,
                    "detail": f"ì „ì²´íˆ¬ìì ìˆœë§¤ìˆ˜í•©ê³„={net_total/1e8:+.1f}ì–µì›",
                    "value": abs(net_total),
                })

    return anomalies


# â”€â”€ ì „ì¼ ì¢…ê°€ ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_prev_close(conn, target_date: date) -> dict[str, float]:
    """target_date ì§ì „ ì˜ì—…ì¼ì˜ ì¢…ê°€ ë”•ì…”ë„ˆë¦¬"""
    with conn.cursor() as cur:
        cur.execute("""
            SELECT DISTINCT ON (stock_code)
                stock_code, close_price
            FROM ohlcv_daily
            WHERE time < %s
            ORDER BY stock_code, time DESC
        """, (target_date,))
        return {row[0]: row[1] for row in cur.fetchall()}


# â”€â”€ ë©”ì¸ ì—…ë°ì´íŠ¸ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_update(target_date: date = None) -> dict:
    """
    ì¼ë³„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
    Returns: ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ë³´ê³ ì„œ ìƒì„±ìš©)
    """
    started_at = datetime.now(KST)
    conn = get_conn()
    client = InfomaxClient()

    # â”€â”€ ì—…ë°ì´íŠ¸ ë‚ ì§œ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if target_date:
        start_date = end_date = target_date
    else:
        start_date, end_date = get_update_range(conn)
        if start_date > end_date:
            print(f"  ì—…ë°ì´íŠ¸í•  ë°ì´í„° ì—†ìŒ (DB ìµœì‹ : {end_date}, ì–´ì œ: {end_date})")
            conn.close()
            return {}

    all_stocks   = get_stocks(conn, include_etf=True)
    kospi_kosdaq = get_stocks(conn, include_etf=False)
    code_to_name = {c: n for c, n in all_stocks}

    total_stocks    = len(all_stocks)
    investor_stocks = len(kospi_kosdaq)

    print(f"\n{'='*70}")
    print(f"  ì¼ë³„ ì—…ë°ì´íŠ¸ ì‹œì‘: {started_at.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  ì—…ë°ì´íŠ¸ ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"  ì „ì²´ ì¢…ëª©: {total_stocks}ê°œ | ìˆ˜ê¸‰ ëŒ€ìƒ: {investor_stocks}ê°œ")
    print(f"{'='*70}\n")

    # ì „ì¼ ì¢…ê°€ (ê¸‰ë“±ë½ ê°ì§€ìš©)
    prev_close = get_prev_close(conn, start_date)

    # â”€â”€ ê²°ê³¼ ì§‘ê³„ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    result = {
        "started_at":     started_at,
        "start_date":     start_date,
        "end_date":       end_date,
        "ohlcv":          {"success": 0, "fail": 0, "rows": 0, "changed": 0, "skipped": 0, "fail_codes": []},
        "market_cap":     {"rows": 0, "changed": 0, "skipped": 0},
        "investor":       {"success": 0, "fail": 0, "rows": 0, "changed": 0, "skipped": 0, "fail_codes": []},
        "ohlcv_data":     [],   # ë¶„ì„ìš© raw rows
        "investor_data":  [],   # ë¶„ì„ìš© raw rows
        "anomalies":      [],
        "errors":         [],
    }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 1: OHLCV + ì‹œê°€ì´ì•¡ ìˆ˜ì§‘ (ì „ ì¢…ëª©, ë³‘ë ¬)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"[1/2] OHLCV + ì‹œê°€ì´ì•¡ ìˆ˜ì§‘ ({total_stocks}ê°œ ì¢…ëª©, workers={MAX_WORKERS})...")

    ohlcv_batch  = []
    mktcap_batch = []
    all_ohlcv_rows = []
    done_count = 0

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(_fetch_hist, client, code, name, start_date, end_date): code
            for code, name in all_stocks
        }
        for future in as_completed(futures):
            code, name, rows = future.result()
            done_count += 1

            if not rows:
                result["ohlcv"]["fail"] += 1
                result["ohlcv"]["fail_codes"].append(code)
            else:
                result["ohlcv"]["success"] += 1
                for r in rows:
                    if r["date"] is None:
                        continue
                    r["stock_name"] = name
                    all_ohlcv_rows.append(r)

                    ohlcv_batch.append((
                        r["date"], r["stock_code"],
                        r["open_price"], r["high_price"],
                        r["low_price"],  r["close_price"],
                        r["volume"],     r["trading_value"],
                    ))

                    if r["close_price"] and r["listed_shares"]:
                        mkt_cap = r["close_price"] * r["listed_shares"]
                        mktcap_batch.append((r["date"], r["stock_code"], mkt_cap))

            # ë°°ì¹˜ ì €ì¥ (500ê±´ë§ˆë‹¤, ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ì‹¤í–‰)
            if len(ohlcv_batch) >= 500:
                ch, tot = upsert_batch(conn, OHLCV_SQL, ohlcv_batch)
                result["ohlcv"]["changed"] += ch
                result["ohlcv"]["skipped"] += tot - ch
                result["ohlcv"]["rows"]    += tot
                ohlcv_batch.clear()
            if len(mktcap_batch) >= 500:
                ch, tot = upsert_batch(conn, MKTCAP_SQL, mktcap_batch)
                result["market_cap"]["changed"] += ch
                result["market_cap"]["skipped"] += tot - ch
                result["market_cap"]["rows"]    += tot
                mktcap_batch.clear()

            if done_count % 500 == 0 or done_count == total_stocks:
                print(f"  [{done_count:4}/{total_stocks}] ì§„í–‰ ì¤‘... (ì„±ê³µ:{result['ohlcv']['success']} ì‹¤íŒ¨:{result['ohlcv']['fail']})")

    # ì”ì—¬ ì €ì¥
    if ohlcv_batch:
        ch, tot = upsert_batch(conn, OHLCV_SQL, ohlcv_batch)
        result["ohlcv"]["changed"] += ch
        result["ohlcv"]["skipped"] += tot - ch
        result["ohlcv"]["rows"]    += tot
    if mktcap_batch:
        ch, tot = upsert_batch(conn, MKTCAP_SQL, mktcap_batch)
        result["market_cap"]["changed"] += ch
        result["market_cap"]["skipped"] += tot - ch
        result["market_cap"]["rows"]    += tot

    result["ohlcv_data"] = all_ohlcv_rows
    print(f"  âœ… OHLCV {result['ohlcv']['rows']:,}ê±´ ì €ì¥ (ë³€ê²½:{result['ohlcv']['changed']:,} / ìŠ¤í‚µ:{result['ohlcv']['skipped']:,})")
    print(f"  âœ… ì‹œê°€ì´ì•¡ {result['market_cap']['rows']:,}ê±´ ì €ì¥ (ë³€ê²½:{result['market_cap']['changed']:,} / ìŠ¤í‚µ:{result['market_cap']['skipped']:,})")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 2: íˆ¬ììë³„ ìˆ˜ê¸‰ ìˆ˜ì§‘ (KOSPI + KOSDAQ, ë³‘ë ¬)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n[2/2] íˆ¬ììë³„ ìˆ˜ê¸‰ ìˆ˜ì§‘ ({investor_stocks}ê°œ ì¢…ëª©, workers={MAX_WORKERS})...")

    investor_batch    = []
    all_investor_rows = []
    done_count = 0

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(_fetch_investor, client, code, name, start_date, end_date): code
            for code, name in kospi_kosdaq
        }
        for future in as_completed(futures):
            code, name, rows = future.result()
            done_count += 1

            if not rows:
                result["investor"]["fail"] += 1
                result["investor"]["fail_codes"].append(code)
            else:
                result["investor"]["success"] += 1
                for r in rows:
                    if r["date"] is None:
                        continue
                    r["stock_name"] = name
                    all_investor_rows.append(r)
                    investor_batch.append((
                        r["date"], r["stock_code"], r["investor_type"],
                        r["net_buy_value"], r["net_buy_volume"],
                    ))

            if len(investor_batch) >= 500:
                ch, tot = upsert_batch(conn, INVESTOR_SQL, investor_batch)
                result["investor"]["changed"] += ch
                result["investor"]["skipped"] += tot - ch
                result["investor"]["rows"]    += tot
                investor_batch.clear()

            if done_count % 500 == 0 or done_count == investor_stocks:
                print(f"  [{done_count:4}/{investor_stocks}] ì§„í–‰ ì¤‘... (ì„±ê³µ:{result['investor']['success']} ì‹¤íŒ¨:{result['investor']['fail']})")

    if investor_batch:
        ch, tot = upsert_batch(conn, INVESTOR_SQL, investor_batch)
        result["investor"]["changed"] += ch
        result["investor"]["skipped"] += tot - ch
        result["investor"]["rows"]    += tot

    result["investor_data"] = all_investor_rows
    print(f"  âœ… ìˆ˜ê¸‰ {result['investor']['rows']:,}ê±´ ì €ì¥ (ë³€ê²½:{result['investor']['changed']:,} / ìŠ¤í‚µ:{result['investor']['skipped']:,})")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 3: íŠ¹ì´ì‚¬í•­ ë¶„ì„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n[ë¶„ì„] íŠ¹ì´ì‚¬í•­ ê°ì§€ ì¤‘...")
    result["anomalies"] = analyze_anomalies(
        result["ohlcv_data"],
        result["investor_data"],
        prev_close,
    )
    print(f"  âœ… íŠ¹ì´ì‚¬í•­ {len(result['anomalies'])}ê±´ ê°ì§€")

    result["finished_at"] = datetime.now(KST)
    conn.close()
    return result


# â”€â”€ ë³´ê³ ì„œ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_report(result: dict) -> str:
    """ìƒì„¸ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ìƒì„±"""
    started  = result["started_at"]
    finished = result["finished_at"]
    elapsed  = (finished - started).total_seconds()
    s_date   = result["start_date"]
    e_date   = result["end_date"]

    ohlcv    = result["ohlcv"]
    mktcap   = result["market_cap"]
    investor = result["investor"]
    anomalies = result["anomalies"]

    lines = []
    W = 72

    def sep(char="="):
        lines.append(char * W)

    def title(text):
        sep()
        lines.append(f"  {text}")
        sep()

    def sub(text):
        lines.append(f"\nâ”€â”€ {text} {'â”€'*(W-5-len(text))}")

    # â”€â”€ í—¤ë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    title("ğŸ“Š ì¼ë³„ ë°ì´í„° ì—…ë°ì´íŠ¸ ë³´ê³ ì„œ")
    lines.append(f"  ì‹¤í–‰ ì¼ì‹œ : {started.strftime('%Y-%m-%d %H:%M:%S KST')}")
    lines.append(f"  ì™„ë£Œ ì¼ì‹œ : {finished.strftime('%Y-%m-%d %H:%M:%S KST')}")
    lines.append(f"  ì†Œìš” ì‹œê°„ : {int(elapsed//3600)}ì‹œê°„ {int(elapsed%3600//60)}ë¶„ {int(elapsed%60)}ì´ˆ")
    lines.append(f"  ì—…ë°ì´íŠ¸ ê¸°ê°„ : {s_date} ~ {e_date}")
    lines.append("")

    # â”€â”€ ìˆ˜ì§‘ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sub("1. ìˆ˜ì§‘ ìš”ì•½")
    lines.append(f"  {'í•­ëª©':<18} {'ì„±ê³µ':>7} {'ì‹¤íŒ¨':>7} {'ì „ì²´ë ˆì½”ë“œ':>11} {'ì‹ ê·œ/ë³€ê²½':>10} {'ìŠ¤í‚µ(ë™ì¼)':>11}")
    lines.append(f"  {'-'*68}")
    lines.append(
        f"  {'OHLCV (ì¼ë´‰)':<18} {ohlcv['success']:>7,} {ohlcv['fail']:>7,} "
        f"{ohlcv['rows']:>11,} {ohlcv['changed']:>10,} {ohlcv['skipped']:>11,}"
    )
    lines.append(
        f"  {'ì‹œê°€ì´ì•¡':<18} {'(OHLCVì™€ ë™ì¼)':>14} "
        f"{mktcap['rows']:>11,} {mktcap['changed']:>10,} {mktcap['skipped']:>11,}"
    )
    lines.append(
        f"  {'íˆ¬ììë³„ ìˆ˜ê¸‰':<18} {investor['success']:>7,} {investor['fail']:>7,} "
        f"{investor['rows']:>11,} {investor['changed']:>10,} {investor['skipped']:>11,}"
    )
    total_rows    = ohlcv['rows']    + mktcap['rows']    + investor['rows']
    total_changed = ohlcv['changed'] + mktcap['changed'] + investor['changed']
    total_skipped = ohlcv['skipped'] + mktcap['skipped'] + investor['skipped']
    lines.append(f"  {'-'*68}")
    lines.append(
        f"  {'í•©ê³„':<18} {'':>14} "
        f"{total_rows:>11,} {total_changed:>10,} {total_skipped:>11,}"
    )
    lines.append("")

    # â”€â”€ í…Œì´ë¸”ë³„ ìƒì„¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sub("2. í…Œì´ë¸”ë³„ ìƒì„¸ ê²°ê³¼")

    lines.append(f"\n  [ohlcv_daily]")
    lines.append(f"    ì „ì²´ ê±´ìˆ˜  : {ohlcv['rows']:,}ê±´")
    lines.append(f"    ì‹ ê·œ/ë³€ê²½  : {ohlcv['changed']:,}ê±´")
    lines.append(f"    ìŠ¤í‚µ(ë™ì¼) : {ohlcv['skipped']:,}ê±´")
    lines.append(f"    ì„±ê³µ ì¢…ëª©  : {ohlcv['success']:,}ê°œ")
    lines.append(f"    ì‹¤íŒ¨ ì¢…ëª©  : {ohlcv['fail']:,}ê°œ")
    if ohlcv['fail_codes']:
        codes_str = ', '.join(ohlcv['fail_codes'][:20])
        suffix = f" ì™¸ {ohlcv['fail']-20}ê°œ" if ohlcv['fail'] > 20 else ""
        lines.append(f"    ì‹¤íŒ¨ ì½”ë“œ  : {codes_str}{suffix}")

    lines.append(f"\n  [market_cap_daily]")
    lines.append(f"    ì „ì²´ ê±´ìˆ˜  : {mktcap['rows']:,}ê±´")
    lines.append(f"    ì‹ ê·œ/ë³€ê²½  : {mktcap['changed']:,}ê±´")
    lines.append(f"    ìŠ¤í‚µ(ë™ì¼) : {mktcap['skipped']:,}ê±´")
    lines.append(f"    ì‚°ì¶œ ë°©ì‹  : close_price Ã— listed_shares (hist API)")

    lines.append(f"\n  [investor_trading]")
    lines.append(f"    ì „ì²´ ê±´ìˆ˜  : {investor['rows']:,}ê±´")
    lines.append(f"    ì‹ ê·œ/ë³€ê²½  : {investor['changed']:,}ê±´")
    lines.append(f"    ìŠ¤í‚µ(ë™ì¼) : {investor['skipped']:,}ê±´")
    lines.append(f"    ì„±ê³µ ì¢…ëª©  : {investor['success']:,}ê°œ")
    lines.append(f"    ì‹¤íŒ¨ ì¢…ëª©  : {investor['fail']:,}ê°œ")
    if investor['fail_codes']:
        codes_str = ', '.join(investor['fail_codes'][:20])
        suffix = f" ì™¸ {investor['fail']-20}ê°œ" if investor['fail'] > 20 else ""
        lines.append(f"    ì‹¤íŒ¨ ì½”ë“œ  : {codes_str}{suffix}")
    lines.append("")

    # â”€â”€ íŠ¹ì´ì‚¬í•­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sub("3. íŠ¹ì´ì‚¬í•­")

    if not anomalies:
        lines.append("\n  âœ… íŠ¹ì´ì‚¬í•­ ì—†ìŒ")
    else:
        # ìœ í˜•ë³„ ë¶„ë¥˜
        by_type = defaultdict(list)
        for a in anomalies:
            by_type[a["type"]].append(a)

        type_order = ["ê±°ë˜ì •ì§€", "OHLCVì˜¤ë¥˜", "ê°€ê²©ê¸‰ë“±", "ê°€ê²©ê¸‰ë½",
                      "ëŒ€ê·œëª¨ìˆœë§¤ìˆ˜", "ëŒ€ê·œëª¨ìˆœë§¤ë„"]
        sorted_types = sorted(by_type.keys(),
                              key=lambda t: type_order.index(t) if t in type_order else 99)

        lines.append(f"\n  ì´ {len(anomalies)}ê±´ì˜ íŠ¹ì´ì‚¬í•­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

        for atype in sorted_types:
            items = by_type[atype]
            emoji = {
                "ê±°ë˜ì •ì§€":     "ğŸ”´",
                "OHLCVì˜¤ë¥˜":    "âŒ",
                "ê°€ê²©ê¸‰ë“±":     "ğŸ“ˆ",
                "ê°€ê²©ê¸‰ë½":     "ğŸ“‰",
                "ëŒ€ê·œëª¨ìˆœë§¤ìˆ˜": "ğŸ’°",
                "ëŒ€ê·œëª¨ìˆœë§¤ë„": "ğŸ’¸",
            }.get(atype, "âš ï¸")

            lines.append(f"  {emoji} [{atype}] {len(items)}ê±´")
            lines.append(f"  {'ë‚ ì§œ':<12} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<18} {'ìƒì„¸'}")
            lines.append(f"  {'-'*68}")
            # ê°€ì¥ í° ê°’ ìˆœìœ¼ë¡œ ì •ë ¬
            for a in sorted(items, key=lambda x: abs(x.get("value", 0) or 0), reverse=True):
                dt_str   = str(a["date"]) if a["date"] else "-"
                lines.append(
                    f"  {dt_str:<12} {a['stock_code']:<10} "
                    f"{a['stock_name'][:16]:<18} {a['detail']}"
                )
            lines.append("")

    # â”€â”€ ì‹¤íŒ¨ ì¢…ëª© ìƒì„¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if ohlcv['fail'] > 0 or investor['fail'] > 0:
        sub("4. API ìˆ˜ì§‘ ì‹¤íŒ¨ ì¢…ëª©")
        lines.append("\n  â€» ì‹¤íŒ¨ ì›ì¸: API ì‘ë‹µ ì—†ìŒ / í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì—†ìŒ (íœ´ì¥ì¼, ì‹ ê·œìƒì¥ ì „)")

        if ohlcv['fail_codes']:
            lines.append(f"\n  OHLCV ì‹¤íŒ¨ ({ohlcv['fail']}ê°œ):")
            for c in ohlcv['fail_codes']:
                lines.append(f"    - {c}")

        if investor['fail_codes']:
            lines.append(f"\n  ìˆ˜ê¸‰ ì‹¤íŒ¨ ({investor['fail']}ê°œ):")
            for c in investor['fail_codes']:
                lines.append(f"    - {c}")
        lines.append("")

    # â”€â”€ í‘¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sep()
    lines.append(f"  ë³´ê³ ì„œ ìƒì„±: {datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S KST')}")
    sep()

    return "\n".join(lines)


def save_report(report_text: str, target_date: date) -> Path:
    fname = REPORTS_DIR / f"daily_update_{target_date.strftime('%Y%m%d')}.txt"
    fname.write_text(report_text, encoding="utf-8")
    return fname


# â”€â”€ ì§„ì…ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(target_date: date = None):
    try:
        result = run_update(target_date)
        report = generate_report(result)

        # ì½˜ì†” ì¶œë ¥
        print("\n" + report)

        # íŒŒì¼ ì €ì¥
        end_date = result["end_date"]
        fpath = save_report(report, end_date)
        print(f"\nğŸ“ ë³´ê³ ì„œ ì €ì¥: {fpath}")

    except Exception as e:
        err_msg = traceback.format_exc()
        print(f"\nâŒ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{err_msg}", file=sys.stderr)
        # ì˜¤ë¥˜ ë³´ê³ ì„œ ì €ì¥
        today = datetime.now(KST).date()
        err_report = f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨\nì‹¤í–‰ì‹œê°: {datetime.now(KST)}\n\n{err_msg}"
        fpath = REPORTS_DIR / f"daily_update_{today.strftime('%Y%m%d')}_ERROR.txt"
        fpath.write_text(err_report, encoding="utf-8")
        sys.exit(1)


if __name__ == "__main__":
    if len(sys.argv) > 1:
        try:
            td = datetime.strptime(sys.argv[1], "%Y%m%d").date()
        except ValueError:
            print("ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜. ì‚¬ìš©ë²•: python daily_update.py YYYYMMDD")
            sys.exit(1)
    else:
        td = None

    main(td)
